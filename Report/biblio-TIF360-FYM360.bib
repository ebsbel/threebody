@article{valtonen2006three,
  title={The three-body problem},
  author={Valtonen, Mauri and Karttunen, Hannu},
  journal={Cambridge University Press},
  year={2006},
  url={https://www.cambridge.org/core/books/threebody-problem/7A0E7E318573D1BE8A00A50B4D3A4813}
}


@article{grebogi1983final,
  title={Final state sensitivity: an obstruction to predictability},
  author={Grebogi, Celso and Ott, Edward and Yorke, James A},
  journal={Physics Letters A},
  volume={99},
  number={9},
  pages={415--418},
  year={1983},
  publisher={Elsevier},
  url={https://www.sciencedirect.com/science/article/abs/pii/0375960183909453}
}


@article{vlachas2018data,
  title={Data-driven forecasting of high-dimensional chaotic systems with long short-term memory networks},
  author={Vlachas, Pantelis R and Byeon, Wonsik and Wan, Zongyi and Sapsis, Themistoklis P and Koumoutsakos, Petros},
  journal={Proceedings of the Royal Society A},
  volume={474},
  number={2213},
  pages={20170844},
  year={2018},
  publisher={The Royal Society},
  url={https://doi.org/10.1098/rspa.2017.0844}
}

@inproceedings{pathak2018model,
  title={Model-free prediction of large spatiotemporally chaotic systems from data: A reservoir computing approach},
  author={Pathak, Jaideep and Lu, Zhen and Hunt, Brian R and Girvan, Michelle and Ott, Edward},
  booktitle={Physical Review Letters},
  volume={120},
  number={2},
  pages={024102},
  year={2018},
  url={https://doi.org/10.1103/PhysRevLett.120.024102}
}

@article{Bocquet_2020,
   title={Bayesian inference of chaotic dynamics by merging data assimilation, machine learning and expectation-maximization},
   volume={2},
   ISSN={2639-8001},
   url={http://dx.doi.org/10.3934/fods.2020004},
   DOI={10.3934/fods.2020004},
   number={1},
   journal={Foundations of Data Science},
   publisher={American Institute of Mathematical Sciences (AIMS)},
   author={Bocquet, Marc and Brajard, Julien and Carrassi, Alberto and Bertino, Laurent},
   year={2020},
   pages={55–80}
}


@article{Kobayashi_PhysRevE.104.044215,
  title = {Dynamical system analysis of a data-driven model constructed by reservoir computing},
  author = {Kobayashi, Miki U. and Nakai, Kengo and Saiki, Yoshitaka and Tsutsumi, Natsuki},
  journal = {Phys. Rev. E},
  volume = {104},
  issue = {4},
  pages = {044215},
  numpages = {7},
  year = {2021},
  month = {Oct},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevE.104.044215},
  url = {https://link.aps.org/doi/10.1103/PhysRevE.104.044215}
}

@article{Pandey_PhysRevFluids.5.113506,
  title = {Reservoir computing model of two-dimensional turbulent convection},
  author = {Pandey, Sandeep and Schumacher, J\"org},
  journal = {Phys. Rev. Fluids},
  volume = {5},
  issue = {11},
  pages = {113506},
  numpages = {18},
  year = {2020},
  month = {Nov},
  publisher = {American Physical Society},
  doi = {10.1103/PhysRevFluids.5.113506},
  url = {https://link.aps.org/doi/10.1103/PhysRevFluids.5.113506}
}


@misc{brenner2025learninginterpretablehierarchicaldynamical,
      title={Learning Interpretable Hierarchical Dynamical Systems Models from Time Series Data}, 
      author={Manuel Brenner and Elias Weber and Georgia Koppe and Daniel Durstewitz},
      year={2025},
      eprint={2410.04814},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2410.04814}, 
}

@article{Chattopadhyay2019,
  author       = {Ashesh Chattopadhyay and
                  Pedram Hassanzadeh and
                  Krishna V. Palem and
                  Devika Subramanian},
  title        = {Data-driven prediction of a multi-scale Lorenz 96 chaotic system using
                  a hierarchy of deep learning methods: Reservoir computing, ANN, and
                  {RNN-LSTM}},
  journal      = {CoRR},
  volume       = {abs/1906.08829},
  year         = {2019},
  url          = {http://arxiv.org/abs/1906.08829},
  eprinttype    = {arXiv},
  eprint       = {1906.08829},
  timestamp    = {Fri, 19 Jul 2019 09:36:56 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-1906-08829.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{Yanan_2020,
doi = {10.1088/1742-6596/1617/1/012094},
url = {https://dx.doi.org/10.1088/1742-6596/1617/1/012094},
year = {2020},
month = {aug},
publisher = {IOP Publishing},
volume = {1617},
number = {1},
pages = {012094},
author = {Yanan, Guo and Xiaoqun, Cao and Bainian, Liu and Kecheng, Peng},
title = {Chaotic Time Series Prediction Using LSTM with CEEMDAN},
journal = {Journal of Physics: Conference Series},
abstract = {Chaotic systems are complex dynamical systems that play a very important role in the study of the atmosphere, aerospace engineering, finance, etc. To improve the accuracy of chaotic time series prediction, this study proposes a hybrid model CEEMDAN-LSTM which combines Complete Ensemble Empirical Mode Decomposition with Adaptive Noise (CEEMDAN) and long short-term memory (LSTM). In the model, the original time series is decomposed into several intrinsic mode functions (IMFs) and a residual component. To reduce the difficulty of predicting chaotic time series and provide a high level of predictive accuracy, the LSTM prediction model is built for all each characteristic series from CEEMDAN deposition. Finally, the final prediction results are obtained by combining all the prediction sequences. To test the effectiveness of this model we proposed, we examined the CEEMDAN-LSTM model using the Lorenz-63 system. Further compared to Autoregressive Integrated Moving Average (ARIMA ), Support Vector Regression (SVR), multilayer perceptron (MLP), and the single LSTM model, the results of the experiment show that the proposed model performs better in the prediction of chaotic time series. Besides, the hybrid model proposed in this paper has better results than the LSTM model alone. Therefore, hybrid models based on deep learning methods and signal decomposition methods have great potential in the field of chaotic time series prediction.}
}

@article{Xue2020,
  author    = {Yanwen Xue and Jun Jiang and Ling Hong},
  title     = {A LSTM based prediction model for nonlinear dynamical systems with chaotic itinerancy},
  journal   = {International Journal of Dynamics and Control},
  year      = {2020},
  volume    = {8},
  number    = {4},
  pages     = {1117--1128},
  doi       = {10.1007/s40435-020-00673-4},
  url       = {https://doi.org/10.1007/s40435-020-00673-4},
  issn      = {2195-2698}
}

@article{VALLE2025116034,
title = {Forecasting chaotic time series: Comparative performance of LSTM-based and Transformer-based neural network},
journal = {Chaos, Solitons & Fractals},
volume = {192},
pages = {116034},
year = {2025},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2025.116034},
url = {https://www.sciencedirect.com/science/article/pii/S0960077925000475},
author = {JoÃ£o Valle and Odemir Martinez Bruno},
keywords = {Deep learning, Time series, Chaos theory},
abstract = {The complexity and sensitivity to initial conditions are the main characteristics of chaotic dynamical systems, making long-term forecasting a significant challenge. Deep learning
            , however, is a powerful technique that can potentially improve forecasting in chaotic time series. In this study, we explored the performance of modern neural network architectures in forecasting chaotic time series with different Lyapunov exponents. To accomplish this, we created a robust dataset composed of chaotic orbits with Lyapunov exponents ranging from 0.019 to 1.253 and used state-of-the-art neural network models for time series forecasting, including recurrent-based and transformer-based architectures. Our results show that LSTNet presents the best results in one-step-ahead and the recursive one-step-ahead forecasting for the majority of the time series in our dataset, enabling the prediction of chaotic time series with high Lyapunov exponent. Additionally, we observed that the sensitivity to initial conditions and complexity still affects the performance of the neural networks, decaying predictive power in time series with larger Lyapunov exponent.}
}


@Article{e23111491,
AUTHOR = {Meng, Xiangyi and Yang, Tong},
TITLE = {Entanglement-Structured LSTM Boosts Chaotic Time Series Forecasting},
JOURNAL = {Entropy},
VOLUME = {23},
YEAR = {2021},
NUMBER = {11},
ARTICLE-NUMBER = {1491},
URL = {https://www.mdpi.com/1099-4300/23/11/1491},
PubMedID = {34828189},
ISSN = {1099-4300},
ABSTRACT = {Traditional machine-learning methods are inefficient in capturing chaos in nonlinear dynamical systems, especially when the time difference Δt between consecutive steps is so large that the extracted time series looks apparently random. Here, we introduce a new long-short-term-memory (LSTM)-based recurrent architecture by tensorizing the cell-state-to-state propagation therein, maintaining the long-term memory feature of LSTM, while simultaneously enhancing the learning of short-term nonlinear complexity. We stress that the global minima of training can be most efficiently reached by our tensor structure where all nonlinear terms, up to some polynomial order, are treated explicitly and weighted equally. The efficiency and generality of our architecture are systematically investigated and tested through theoretical analysis and experimental examinations. In our design, we have explicitly used two different many-body entanglement structures—matrix product states (MPS) and the multiscale entanglement renormalization ansatz (MERA)—as physics-inspired tensor decomposition techniques, from which we find that MERA generally performs better than MPS, hence conjecturing that the learnability of chaos is determined not only by the number of free parameters but also the tensor complexity—recognized as how entanglement entropy scales with varying matricization of the tensor.},
DOI = {10.3390/e23111491}
}

@misc{bai2018empiricalevaluationgenericconvolutional,
      title={An Empirical Evaluation of Generic Convolutional and Recurrent Networks for Sequence Modeling}, 
      author={Shaojie Bai and J. Zico Kolter and Vladlen Koltun},
      year={2018},
      eprint={1803.01271},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1803.01271}, 
}

@article{lorenz1963deterministic,
  title={Deterministic nonperiodic flow},
  author={Lorenz, Edward N},
  journal={Journal of the Atmospheric Sciences},
  volume={20},
  number={2},
  pages={130--141},
  year={1963},
  publisher={American Meteorological Society},
  doi={10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2},
  url={https://doi.org/10.1175/1520-0469(1963)020<0130:DNF>2.0.CO;2}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural Computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press},
  doi={10.1162/neco.1997.9.8.1735},
  url={https://doi.org/10.1162/neco.1997.9.8.1735}
}

@article{RAISSI2019686,
title = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
journal = {Journal of Computational Physics},
volume = {378},
pages = {686-707},
year = {2019},
issn = {0021-9991},
doi = {https://doi.org/10.1016/j.jcp.2018.10.045},
url = {https://www.sciencedirect.com/science/article/pii/S0021999118307125},
author = {M. Raissi and P. Perdikaris and G.E. Karniadakis},
keywords = {Data-driven scientific computing, Machine learning, Predictive modeling, Runge–Kutta methods, Nonlinear dynamics},
abstract = {We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge–Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction–diffusion systems, and the propagation of nonlinear shallow-water waves.}
}